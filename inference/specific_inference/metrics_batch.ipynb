{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "import faiss\n",
    "import json\n",
    "import tempfile\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Path to append for imports\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from inference.create_img import convert_mario_to_png\n",
    "\n",
    "# Functions from level_similarity_search.py\n",
    "def load_json_data(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def load_level_search_index(index_path):\n",
    "    \"\"\"Load the FAISS index and level indices\"\"\"\n",
    "    index = faiss.read_index(index_path)\n",
    "    with open(index_path + \".indices\", \"r\") as f:\n",
    "        level_indices = [int(line.strip()) for line in f]\n",
    "    print(f\"Index loaded from {index_path}\")\n",
    "    return index, level_indices\n",
    "\n",
    "# Function to create level data structure expected by the system\n",
    "def create_level_data(level_string):\n",
    "    # Split by newlines\n",
    "    rows = level_string.split(\"\\n\")\n",
    "    # Also check for | separator and split if present\n",
    "    processed_rows = []\n",
    "    for row in rows:\n",
    "        if \"|\" in row:\n",
    "            # Split by | and keep non-empty parts\n",
    "            parts = [p for p in row.split(\"|\") if p]\n",
    "            processed_rows.extend(parts)\n",
    "        else:\n",
    "            processed_rows.append(row)\n",
    "    \n",
    "    # Create the window representation\n",
    "    window = processed_rows\n",
    "    \n",
    "    # Create level data structure\n",
    "    level_data = {\n",
    "        \"window\": window,\n",
    "        \"level_string\": level_string\n",
    "    }\n",
    "    \n",
    "    return level_data\n",
    "\n",
    "def generate_level_embedding(level_data, model, processor, game_type):\n",
    "    \"\"\"Process a level into an embedding\"\"\"\n",
    "    window = level_data[\"window\"]\n",
    "    \n",
    "    # Create level image\n",
    "    if game_type == \"mario\":\n",
    "        img, _, _ = convert_mario_to_png(\"\\n\".join(window), tiles_dir=\"../../assets/mario\")\n",
    "    else:\n",
    "        raise ValueError(f\"Game type {game_type} not supported yet\")\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp_file:\n",
    "        temp_path = temp_file.name\n",
    "        img.save(temp_path)\n",
    "\n",
    "    try:\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\", \"url\": f\"{temp_path}\"},\n",
    "                ]\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        inputs = processor.apply_chat_template(\n",
    "            messages,\n",
    "            add_generation_prompt=True,\n",
    "            tokenize=True,\n",
    "            return_dict=True,\n",
    "            return_tensors=\"pt\",\n",
    "        ).to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            embedding = outputs.image_hidden_states.cpu().numpy()\n",
    "\n",
    "        return embedding\n",
    "\n",
    "    finally:\n",
    "        if os.path.exists(temp_path):\n",
    "            os.remove(temp_path)\n",
    "\n",
    "def search_similar_levels(query_level_data, model, processor, index, level_indices, game_type, top_k=5):\n",
    "    \"\"\"Find similar levels to the query level\"\"\"\n",
    "    query_features = generate_level_embedding(query_level_data, model, processor, game_type)\n",
    "    query_features = query_features.astype(np.float32).reshape(1, -1)\n",
    "\n",
    "    faiss.normalize_L2(query_features)\n",
    "\n",
    "    distances, indices = index.search(query_features, top_k)\n",
    "    similarities = (distances + 1) / 2\n",
    "\n",
    "    similar_level_indices = [level_indices[int(idx)] for idx in indices[0]]\n",
    "\n",
    "    return similar_level_indices, similarities[0]\n",
    "\n",
    "# --- Main Processing Code ---\n",
    "\n",
    "# Load the JSON file with levels\n",
    "input_json_path = \"level_generation_results_20250521_100328.json\"\n",
    "levels_data = load_json_data(input_json_path)\n",
    "\n",
    "# Set up the game type and embedding directory\n",
    "game_type = \"mario\"\n",
    "embedding_dir = f\"embeddings_{game_type}\"\n",
    "top_k = 5  # Number of similar levels to find\n",
    "\n",
    "# Load the model and processor (do this once to avoid reloading for each level)\n",
    "print(\"Loading models...\")\n",
    "processor = AutoProcessor.from_pretrained(\"HuggingFaceTB/SmolVLM2-2.2B-Instruct\")\n",
    "model = AutoModelForImageTextToText.from_pretrained(\"HuggingFaceTB/SmolVLM2-2.2B-Instruct\")\n",
    "\n",
    "# Load the search index\n",
    "index, level_indices = load_level_search_index(f\"{embedding_dir}/level_index.faiss\")\n",
    "\n",
    "# Function to process a single level\n",
    "def process_level(level_entry):\n",
    "    try:\n",
    "        level_string = level_entry[\"level\"]\n",
    "        level_data = create_level_data(level_string)\n",
    "        \n",
    "        # Run similarity search\n",
    "        similar_indices, similarities = search_similar_levels(\n",
    "            level_data, model, processor, index, level_indices, game_type, top_k=top_k\n",
    "        )\n",
    "        \n",
    "        # Add similarity results to the entry\n",
    "        level_entry[\"similarity_results\"] = {\n",
    "            \"similar_levels\": [int(idx) for idx in similar_indices],\n",
    "            \"similarity_scores\": [float(score) for score in similarities]\n",
    "        }\n",
    "        \n",
    "        return level_entry\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing level: {str(e)}\")\n",
    "        level_entry[\"similarity_results\"] = {\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "        return level_entry\n",
    "\n",
    "# Process levels in parallel to speed things up\n",
    "print(f\"Processing {len(levels_data)} levels...\")\n",
    "processed_levels = []\n",
    "\n",
    "# Use a progress bar to track the processing\n",
    "with tqdm.tqdm(total=len(levels_data)) as pbar:\n",
    "    # Process levels in smaller batches to avoid memory issues\n",
    "    batch_size = 10\n",
    "    for i in range(0, len(levels_data), batch_size):\n",
    "        batch = levels_data[i:i+batch_size]\n",
    "        \n",
    "        # Process batch\n",
    "        with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "            for result in executor.map(process_level, batch):\n",
    "                processed_levels.append(result)\n",
    "                pbar.update(1)\n",
    "        \n",
    "        # Clear GPU memory between batches\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# Save the results to a new JSON file\n",
    "output_json = \"levels_with_similarity_metrics.json\"\n",
    "with open(output_json, \"w\") as f:\n",
    "    json.dump(processed_levels, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to {output_json}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mario_emb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
